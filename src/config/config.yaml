training: !!bool "true"
device: "cpu"
unprocessed_data: '/DATA/datasets/TIMIT_wav/**/**/**/*.wav'
---
data:
  train_path: '/DATA/datasets/train_tisv'
  train_path_unprocessed: '/DATA/datasets/TIMIT/TRAIN/*/*/*.wav'
  test_path: '/DATA/datasets/test_tisv'
  test_path_unprocessed: '/DATA/datasets/TIMIT/TEST/*/*/*.wav'
#  data_preprocessed: !!bool "false"
  sr: 16000
  nfft: 512 #For mel spectrogram preprocess
  window: 0.025 #(s)
  hop: 0.01 #(s)
  nmels: 40 #Number of mel energies
  tisv_frame: 180 #Max number of time steps in input after preprocess
---
model:
  #  --rnn_hidden_size 512
  hidden: 768 #Number of LSTM hidden layer units
  num_layer: 3 #Number of LSTM layers
  #  uis-rnn --observation_dim 256
  proj: 256 #Embedding size
  model_path: '/DATA/models/final_epoch_512_batch_id_141.model' #Model path for testing, inference, or resuming training
---
train:
  N : 4 #Number of speakers in batch
  M : 5 #Number of utterances per speaker
  num_workers: 0 #number of workers for data loader
  lr: 0.01
  epochs: 512 #Max training speaker epoch
  log_interval: 1 #Epochs before printing progress
  log_file: '/DATA/models/speech_id_checkpoint/Stats'
  checkpoint_interval: 1 #Save model after x speaker epochs
  checkpoint_dir: '/DATA/models/speech_id_checkpoint/'
  restore: !!bool "true" #Resume training from previous model path
---
test:
  N : 4 #Number of speakers in batch
  M : 6 #Number of utterances per speaker
  num_workers: 0 #number of workers for data laoder
  epochs: 10 #testing speaker epochs
